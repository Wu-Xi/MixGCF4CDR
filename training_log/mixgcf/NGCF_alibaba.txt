nohup: ignoring input
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |       Loss       |               recall               |                ndcg                |                   precision                    |             hit_ratio              |
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
|   0   | 165.2075068950653 | 127.84148979187012 | 498.186279296875 | [0.00672941 0.01065944 0.01379493] | [0.00305503 0.00391296 0.00451481] |       [0.0004826  0.00037298 0.00032219]       | [0.00887982 0.01365065 0.01741492] |
|   0   | 165.2075068950653 | 150.38513207435608 | 498.186279296875 | [0.00101009 0.00229109 0.0034104 ] | [0.00037736 0.0006629  0.00087811] | [6.87127806e-05 8.31202991e-05 8.27508755e-05] | [0.00130037 0.00308838 0.00447741] |
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
using time 125.7202s, training loss at epoch 1: 497.3849
using time 115.9505s, training loss at epoch 2: 492.5753
using time 133.3256s, training loss at epoch 3: 457.0482
using time 174.2572s, training loss at epoch 4: 415.9743
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 162.45854306221008 | 131.21010041236877 | 401.30633544921875 | [0.04117442 0.05917832 0.07291735] | [0.01916144 0.02306596 0.02565961] | [0.002504   0.00183457 0.00152501] | [0.0482461  0.06968728 0.08576471] |
|   5   | 162.45854306221008 | 105.77683115005493 | 401.30633544921875 | [0.01306111 0.02104372 0.02722392] | [0.00577334 0.00744721 0.00859142] | [0.00071151 0.00058517 0.00051695] | [0.01405287 0.0230077  0.03017452] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 157.0744s, training loss at epoch 6: 390.9208
using time 162.5529s, training loss at epoch 7: 381.6571
using time 174.6575s, training loss at epoch 8: 373.1204
using time 158.9691s, training loss at epoch 9: 364.4458
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 163.95726537704468 | 107.33438873291016 | 355.5585632324219 | [0.05090556 0.07102082 0.08507466] | [0.02442691 0.02876671 0.03140752] | [0.00308312 0.00218859 0.0017647 ] | [0.0595527  0.08343445 0.0997325 ] |
|   10  | 163.95726537704468 | 88.91106128692627  | 355.5585632324219 | [0.01483246 0.02316981 0.02951175] | [0.00633513 0.00808146 0.00925646] | [0.00078983 0.00063763 0.00055561] | [0.01564878 0.02509125 0.03259793] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 158.1367s, training loss at epoch 11: 346.5846
using time 150.8041s, training loss at epoch 12: 337.2554
using time 139.4621s, training loss at epoch 13: 327.6519
using time 134.8336s, training loss at epoch 14: 317.9373
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 141.7816755771637 | 112.98322796821594 | 307.7481384277344 | [0.05381694 0.07467627 0.08887363] | [0.0259023  0.03041139 0.0330622 ] | [0.00323341 0.00229097 0.00182813] | [0.06254481 0.08726766 0.10355193] |
|   15  | 141.7816755771637 | 87.08580160140991  | 307.7481384277344 | [0.01431281 0.02275866 0.02954238] | [0.00604067 0.00780776 0.00905944] | [0.00076545 0.0006258  0.00055487] | [0.01516114 0.02460361 0.03245016] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 161.3895s, training loss at epoch 16: 297.5210
using time 175.3861s, training loss at epoch 17: 287.3808
using time 160.9310s, training loss at epoch 18: 277.0309
using time 159.5312s, training loss at epoch 19: 266.5396
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 163.18678522109985 | 108.61279940605164 | 256.2170715332031 | [0.05304717 0.07302506 0.08682368] | [0.02580058 0.03011433 0.03270088] | [0.0031755  0.00222823 0.00178332] | [0.06155204 0.08508907 0.10113893] |
|   20  | 163.18678522109985 | 100.19521641731262 | 256.2170715332031 | [0.01410493 0.02221414 0.02899942] | [0.00582408 0.00752695 0.00878315] | [0.0007588  0.0006125  0.00054822] | [0.01501337 0.02417508 0.03199208] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 176.9925s, training loss at epoch 21: 245.9839
using time 161.0181s, training loss at epoch 22: 236.2302
using time 146.7858s, training loss at epoch 23: 226.2955
using time 132.4954s, training loss at epoch 24: 216.7484
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 142.14727568626404 | 145.74753403663635 | 207.36746215820312 | [0.05150505 0.07123476 0.08504004] | [0.02516631 0.02941993 0.0319881 ] | [0.00307967 0.00217135 0.00173736] | [0.05974574 0.08303458 0.09873973] |
|   25  | 142.14727568626404 | 130.04586362838745 | 207.36746215820312 | [0.01378589 0.02187402 0.02835564] | [0.00565877 0.00735898 0.00855258] | [0.00074476 0.00060881 0.0005369 ] | [0.01473261 0.02389432 0.03122368] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 173.6700s, training loss at epoch 26: 198.4358
using time 155.5155s, training loss at epoch 27: 190.0870
using time 161.3146s, training loss at epoch 28: 181.5297
using time 168.9465s, training loss at epoch 29: 173.7460
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 160.85536098480225 | 131.0956835746765 | 166.0374755859375 | [0.04926016 0.06861101 0.0814299 ] | [0.02429792 0.02846045 0.03085422] | [0.00295213 0.00208552 0.00166267] | [0.0572638  0.07975291 0.09460317] |
|   30  | 160.85536098480225 | 99.94862866401672 | 166.0374755859375 | [0.01374217 0.02146198 0.02755981] | [0.00565113 0.00726843 0.00840069] | [0.00074402 0.00059551 0.00052335] | [0.01473261 0.02342145 0.03045528] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 157.0014s, training loss at epoch 31: 159.0043
using time 163.1532s, training loss at epoch 32: 151.9353
using time 171.9185s, training loss at epoch 33: 145.4930
using time 160.3325s, training loss at epoch 34: 139.5190
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 123.52176213264465 | 108.76000261306763 | 133.54190063476562 | [0.04734139 0.0660028  0.07810193] | [0.02335647 0.02736407 0.02962169] | [0.00284182 0.00200554 0.00159373] | [0.05501627 0.07680216 0.09076995] |
|   35  | 123.52176213264465 | 103.3937361240387  | 133.54190063476562 | [0.01343343 0.02128431 0.02714754] | [0.00553004 0.00717673 0.00826637] | [0.00073146 0.00059329 0.00051719] | [0.01446663 0.02322935 0.03007108] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 5 log:0.013433426965411666
early stopping at 35, recall@20:0.0148
